# ATLASky-AI

## Multi-Domain 4D Spatiotemporal Knowledge Graph Verification System

ATLASky-AI is a domain-adaptable verification system for 4D Spatiotemporal Knowledge Graphs (STKGs) that combines physics-based constraints with multi-modal verification to detect and prevent:

- **Content Hallucination**: Fabricated facts not grounded in reality
- **ST-Inconsistency**: Violations of physical laws (spatial/temporal)
- **Semantic Drift**: Facts that deviate from domain ontology

---

## Demo â€” See It In Action

### Dashboard Overview

<p align="center">
  <img src="demo/dashboard_overview.png" alt="ATLASky-AI Dashboard" width="100%">
</p>

The interactive dashboard shows the STKG formalization **G = (V, E, O, T, Î¨)** with live knowledge graph metrics and physics-based consistency predicates:

<p align="center">
  <img src="demo/physics_predicates.png" alt="Physics Predicates Ïˆ_s, Ïˆ_t, Î¨" width="100%">
</p>

### Five-Module Verification Pipeline

Each candidate fact passes through 5 modules sequentially (Mâ‚â†’Mâ‚…), each computing dual metrics. Early termination occurs when cumulative confidence exceeds the global threshold.

<p align="center">
  <img src="demo/methodology_modules.png" alt="Five Verification Modules" width="100%">
</p>

### Verification Results â€” Accept vs. Reject

The system classifies facts as **ST** (spatiotemporal) or **SEM** (semantic-only) and applies a three-way decision: **Accept** / **Review** / **Reject**.

| Verification Result | Screenshot |
|---|---|
| TruthFlow output with module scores, cumulative confidence, and decision logic | <img src="demo/result_high_quality.png" alt="Verification Result" width="500"> |
| Low-quality fact with invalid entity and timestamp correctly **REJECTED** | <img src="demo/result_low_quality.png" alt="Low Quality Rejected" width="500"> |

### AAIC Adaptive Monitoring

The Autonomous Adaptive Intelligence Cycle (AAIC) monitors module performance via CGR-CUSUM and adapts weights, thresholds, and alpha parameters when distribution shifts are detected.

<p align="center">
  <img src="demo/aaic_monitoring.png" alt="AAIC CGR-CUSUM Monitoring" width="100%">
</p>

### CLI Verification Demo

Run `python3 test_verification_demo.py` to see all quality cases processed through the pipeline:

```
================================================================================
  Test Case: HIGH_QUALITY
================================================================================
Candidate Fact Quality: high_quality
Fact Type: ST
Decision: âœ… ACCEPT
Cumulative Confidence: 0.8333 (Threshold: 0.65)
Early Termination: True â€” Terminated at Module: MAV

Activated Modules: LOV, MAV
Module Scores:
  LOV: 0.7000 (threshold: 0.70) [âœ“]  Metric1: 1.0000 | Metric2: 0.0000
  POV: 0.6100 (threshold: 0.70) [âœ—]  Metric1: 0.4000 | Metric2: 1.0000
  MAV: 1.0000 (threshold: 0.65) [âœ“]  Metric1: 1.0000 | Metric2: 1.0000

================================================================================
  Test Case: LOW_QUALITY
================================================================================
Candidate Fact Quality: low_quality
Fact Type: SEM
Decision: âŒ REJECT
Cumulative Confidence: 0.0000 (Threshold: 0.65)
Early Termination: False

Activated Modules: (none)
Module Scores:
  LOV: 0.5333 (threshold: 0.70) [âœ—]  Metric1: 0.3333 | Metric2: 1.0000
  POV: 0.1300 (threshold: 0.70) [âœ—]  Metric1: 0.2000 | Metric2: 0.0000
  MAV: 1.0000 (threshold: 0.65) [âœ“]  Metric1: 1.0000 | Metric2: 1.0000  â† neutral (SEM)
  WSV: 0.3500 (threshold: 0.60) [âœ—]  Metric1: 0.0000 | Metric2: 1.0000
  ESV: 0.5175 (threshold: 0.65) [âœ—]  Metric1: 0.7393 | Metric2: 0.0000
```

**What's happening:**

- **HIGH_QUALITY** â†’ Fact type **ST** (valid coordinates). LOV confirms structural compliance (Metricâ‚=1.0). MAV confirms physics consistency (Ïˆ_s=1, Ïˆ_t=1). Cumulative confidence 0.83 â‰¥ 0.65 â†’ **ACCEPT** with early termination at Mâ‚ƒ.

- **LOW_QUALITY** â†’ Fact type **SEM** (invalid timestamp `202X-12-5`). LOV detects unknown entity class (Metricâ‚=0.33). POV detects non-standard terminology and invalid tools (Metricâ‚=0.20). MAV neutral (SEM fact, physics N/A). WSV finds no corroboration. ESV detects statistical anomaly. No modules reach activation threshold â†’ C=0.0 â†’ **REJECT**.

---

## System Architecture

### 4D STKG Formalization

ATLASky-AI operates on a formal 4D STKG defined as **G = (V, E, O, T, Î¨)** where:

- **V**: Versioned entities with immutable attributes and mutable state
- **E**: Directed edges representing relationships
- **O = (C, R_o, A)**: Domain ontology with entity classes, relation types, and attributes
- **T: (V âˆª E) â†’ â„Â³ Ã— â„**: Maps entities/relations to spatiotemporal coordinates (x,y,z,t)
- **Î¨: (V âˆª E) â†’ {0,1}**: Physical consistency predicate combining spatial (Ïˆ_s) and temporal (Ïˆ_t) consistency

### Physics-Based Predicates

- **Ïˆ_s (Spatial Consistency)**: Prevents co-location violations â€” same entity cannot exist at two separated locations within the same time window
- **Ïˆ_t (Temporal Consistency)**: Enforces velocity and travel-time constraints â€” travel time must be physically feasible given distance and maximum velocity
- **Î¨ = Ïˆ_s âˆ§ Ïˆ_t**: Combined predicate ensuring full physical consistency

### Three-Stage Pipeline

1. **Stage 1 â€” Data Preprocessing**: Normalizes heterogeneous raw data RD into structured format RD' (OCR, spell correction, terminology standardization via ontology O, temporal alignment to UTC, spatial validation via facility maps)
2. **Stage 2 â€” LLM-Based Extraction**: Generates candidate facts D = L(RD'; P) using domain-specialized prompts with confidence-weighted output d_k = âŸ¨s, r, o, T(d_k), conf_kâŸ© where conf_k âˆˆ {high=1.0, medium=0.8, low=0.6}
3. **Stage 3 â€” TruthFlow Verification**: Validates candidates through Ranked Multi-Modal Verification (RMMVe) with Autonomous Adaptive Intelligence Cycle (AAIC)

### Five-Module Verification Pipeline (RMMVe)

Each module M_i computes confidence through two complementary metrics:

**S_i(d_k) = conf_k Ã— [Î±_i Â· Metricâ‚ + (1âˆ’Î±_i) Â· Metricâ‚‚]**

| Module | Full Name | Primary Target | Dual Metrics | Cost |
|--------|-----------|----------------|--------------|------|
| Mâ‚ (LOV) | Lexical-Ontological Verification | Semantic Drift | Structural Compliance (Eq. 8) + Attribute Compliance (Eq. 9) | 5 ms |
| Mâ‚‚ (POV) | Protocol-Ontology Verification | Content Hallucination | Standard Terminology Match (Eq. 10) + Cross-Standard Consistency (Eq. 11) | 15 ms |
| Mâ‚ƒ (MAV) | Motion-Aware Verification | ST-Inconsistency | Temporal-Spatial Validity Ïˆ_s, Ïˆ_t (Eq. 12) + Physical Feasibility min(Kinematic, Process) (Eq. 13-16) | 50 ms |
| Mâ‚„ (WSV) | Web-Source Verification | Content Hallucination | Source Credibility (Eq. 17) + Cross-Source Agreement (Eq. 18) | 120 ms |
| Mâ‚… (ESV) | Embedding Similarity Verification | Semantic Drift + Hallucination | K-NN Cosine Similarity (Eq. 19) + Cluster Membership / GMM (Eq. 20) | 800 ms |

**Key mechanisms:**

- **Fact Type Classification**: Facts are classified as **ST** (spatiotemporal â€” has valid coordinates) or **SEM** (semantic-only). For SEM facts, MAV assigns neutral score Sâ‚ƒ=1.0 (physics not applicable).
- **Critical Module Veto**: For ST facts, if MAV score < Ï„_veto (healthcare: 0.5, aerospace: 0.30) â†’ immediate Reject regardless of other modules.
- **Early Termination**: When cumulative confidence C â‰¥ Î˜ (global threshold), remaining modules are skipped. For ST facts, early termination is suspended until Mâ‚ƒ has executed.
- **Three-Way Decision** (Eq. 23): Accept if C â‰¥ Î˜; Review if Î˜âˆ’Îµ â‰¤ C < Î˜ (Îµ=0.1); Reject if C < Î˜âˆ’Îµ.

### Autonomous Adaptive Intelligence Cycle (AAIC)

AAIC monitors per-module precision via **CGR-CUSUM** (Eq. 24):

**G_i(n) = max(0, G_i(n-1) + [p_i(n) âˆ’ Î¼_0 âˆ’ k])**

where k = 0.5Ïƒ (allowable slack), h = 5Ïƒ (alarm threshold). When G_i(n) â‰¥ h, three-level adaptation triggers:

- **Weight** (Eq. 25): `w_i â† w_i Ã— exp[âˆ’Î³ Â· G_i(t)]`, renormalise Î£w_i = 1 (Î³ = 0.01)
- **Threshold** (Eq. 26): `Î¸_i â† Î¸_i + Î· Â· sign(FPR_i âˆ’ FNR_i)` (Î· = 0.05)
- **Alpha** (Eq. 27): `Î±_i â† Î±_i + Î·' Â· âˆ‚L_i/âˆ‚Î±_i`, clip [0,1] (Î·' = 0.02)

### Defense-in-Depth Architecture

The five-layer verification achieves robustness through three principles:

1. **Independence**: Modules operate on distinct information sources (ontology, standards, physics, web, embeddings)
2. **Complementarity**: Modules target different error classes â€” ontology-compliant fabrications evade Mâ‚/Mâ‚ƒ but are caught by Mâ‚‚/Mâ‚„
3. **Redundancy**: Hallucination covered by both Mâ‚‚ (terminology) and Mâ‚„ (external evidence); Drift covered by both Mâ‚ (ontology) and Mâ‚… (embeddings)

### Domain Adaptation Protocol

Deploying in new domains requires configuring five components:

1. **Domain Ontology (O)**: Entity classes C, relation types R_o, attributes A (50â€“200 classes typical)
2. **Industry Standards (Mâ‚‚)**: STEP AP242 for aerospace, HL7 FHIR for healthcare, ISA-95 for manufacturing
3. **Physical Constraints (Mâ‚ƒ)**: Max velocities v_max, minimum process durations, facility geometry, veto threshold Ï„_veto
4. **Source Credibility (Mâ‚„)**: Credibility weights w_cred per source type (government > manufacturer > academic > news)
5. **Domain Embeddings (Mâ‚…)**: Sentence-transformers on â‰¥10K historical facts, quarterly retraining

## Key Features

- **Multi-Domain Support** â€” Aerospace, Healthcare, Aviation, CAD/Engineering
- **Physics-Based Verification** â€” Enforces Ïˆ_s (bilocation) and Ïˆ_t (velocity/travel-time) consistency
- **Three-Stage Pipeline** â€” Data Preprocessing â†’ LLM Extraction â†’ TruthFlow Verification
- **Adaptive Intelligence** â€” AAIC auto-adjusts w, Î¸, Î± via CGR-CUSUM monitoring
- **Honest Verification** â€” Real ontology checking, real standard terminology matching, real embedding similarity
- **ST/SEM Fact Classification** â€” Physics checks applied only to spatiotemporal facts
- **Critical Module Veto** â€” MAV can immediately reject physically impossible ST facts
- **Automatic STKG Integration** â€” Accepted facts added to knowledge graph
- **Interactive Visualization** â€” 7 dashboard tabs:
  - ğŸ“š Methodology â€” STKG formalization, physics predicates, error taxonomy, five-module pipeline
  - ğŸŒ Domain Configuration â€” Load/edit domain configs (ontology, standards, physics, credibility, embeddings)
  - ğŸ—‚ï¸ STKG Structure â€” Knowledge graph visualization, domain examples, ontology browser
  - ğŸ’  Verification Process â€” Three-stage pipeline with upload/processing capabilities
  - ğŸ”„ AAIC Monitoring â€” CGR-CUSUM tracking and parameter shift detection
  - ğŸ“Š Parameter Evolution â€” Weight, threshold, and alpha adaptation over time
  - ğŸ“œ Verification History â€” Complete audit trail of all verifications

## Getting Started

### Prerequisites

- Python 3.8+
- Dependencies listed in `requirements.txt`:
  - `streamlit>=1.24.0`
  - `pandas>=1.5.0`
  - `numpy>=1.23.0`
  - `matplotlib>=3.6.0`
  - `plotly>=5.14.0`

### Installation

```bash
pip install -r requirements.txt
```

### Running the Application

```bash
streamlit run app.py
```

The dashboard opens at `http://localhost:8501`.

## Code Structure

```
â”œâ”€â”€ app.py                          # Main Streamlit application (7 tabs)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ knowledge_graph.py          # 4D STKG with physics predicates (Ïˆ_s, Ïˆ_t, Î¨)
â”‚   â”œâ”€â”€ ontology.py                 # Multi-domain ontology (16 entity classes, 11 relationships)
â”‚   â””â”€â”€ constants.py                # Physical params, veto thresholds, CUSUM params, standard terminologies
â”œâ”€â”€ verification/
â”‚   â”œâ”€â”€ rmmve.py                    # RMMVe: ST/SEM classification, veto, 3-way decision, early termination
â”‚   â”œâ”€â”€ modules.py                  # 5 modules (LOV, POV, MAV, WSV, ESV) with real dual-metric implementations
â”‚   â”œâ”€â”€ base.py                     # Base module: S_i = conf_k Ã— [Î±Â·M1 + (1âˆ’Î±)Â·M2]
â”‚   â”œâ”€â”€ domain_adapter.py           # Domain adaptation (5-component configuration)
â”‚   â””â”€â”€ defense_in_depth.py         # Defense-in-Depth analysis (independence, complementarity, redundancy)
â”œâ”€â”€ aaic/
â”‚   â””â”€â”€ aaic.py                     # CGR-CUSUM monitoring, FPR/FNR threshold, loss-gradient alpha
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocessing.py            # Stage 1: RD â†’ RD' (OCR, spell correction, temporal alignment, spatial mapping)
â”‚   â”œâ”€â”€ llm_extraction.py           # Stage 2: D = L(RD'; P) with confidence {high:1.0, medium:0.8, low:0.6}
â”‚   â”œâ”€â”€ generators.py               # Test data with quality-specific issues (semantic, spatial, low)
â”‚   â””â”€â”€ quality_based_generator.py  # Raw text generation for honest testing
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ run_experiments.py          # Full experiment runner across 4 domains
â”‚   â”œâ”€â”€ quick_demo.py               # Quick CLI demo
â”‚   â”œâ”€â”€ datasets/                   # Domain-specific dataset generators
â”‚   â””â”€â”€ metrics/                    # Evaluation: Precision, Recall, F1, FPR
â”œâ”€â”€ visualization/                  # Plotly charts and Streamlit UI components
â”œâ”€â”€ utils/                          # CSS styles
â””â”€â”€ domains/                        # Domain configuration JSON files
```

## Usage

### Interactive Dashboard

```bash
streamlit run app.py
```

**Basic Workflow:**

1. **Generate Test Fact** (Sidebar): Select domain and quality level â†’ Click "ğŸ² Generate Test Fact"
2. **Run Verification** (Verification Process Tab): Stage 1 â†’ Stage 2 â†’ Stage 3
3. **View Results**: Decision (Accept/Review/Reject), fact type (ST/SEM), module scores, cumulative confidence

**Or Upload Your Own Data:**
- Stage 1: Upload TXT/JSON file â†’ Configure domain â†’ Run preprocessing
- Stage 2: Extract facts with domain-specialized LLM prompts
- Stage 3: Verify via RMMVe + AAIC and integrate accepted facts into STKG

### Command-Line Testing

```bash
# Verification pipeline demo (high, medium, spatial, low quality)
python3 test_verification_demo.py

# Quick experiment demo with metrics
python3 experiments/quick_demo.py

# Full experiments on specific or all datasets
python3 experiments/run_experiments.py --dataset manufacturing --num-facts 100
python3 experiments/run_experiments.py --all --num-facts 100

# Domain adaptation test
python3 test_domain_adaptation.py
```

Results are saved to `experiments/results/` as JSON with complete metrics and confusion matrices.

## License

This project is for demonstration purposes only.
